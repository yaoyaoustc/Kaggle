{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this notebook is used to build train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%run /Users/yaoyao/Documents/datascience/toolbox/toolbox1_dataview.ipynb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libs and readin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.csv') as f:\n",
    "    raw_train = pd.read_csv(f)\n",
    "with open('test.csv') as f:\n",
    "    raw_test = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw clean the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_devive(train):\n",
    "    # 1. we're predicting the attempts of last assessment for every installid\n",
    "    # so first we need to remove other activities after the last assessment\n",
    "    idlist = train['installation_id'].unique()\n",
    "    greplast = train.drop_duplicates(subset = 'installation_id',keep='last').index\n",
    "    dictionary = dict(zip(idlist, greplast))\n",
    "    del idlist\n",
    "    del greplast\n",
    "    return dictionary\n",
    "\n",
    "def train_clean(raw_train):\n",
    "    # 1.get installation_id with only one game session\n",
    "    # all records doing assessments\n",
    "    astrain = raw_train[raw_train['type'] == 'Assessment'].loc[:,['installation_id','game_session']]\n",
    "    # all insid ever done assessment\n",
    "    inid2keep = astrain.groupby('installation_id').count().index\n",
    "    train = raw_train[raw_train['installation_id'].isin(inid2keep)]\n",
    "    \n",
    "    #2, remove last events are not assessment\n",
    "    # loop through devices to find index need to be dropped.\n",
    "    dictionary = get_devive(train)\n",
    "    train_cp = train.loc[:,['game_session','type','installation_id']]\n",
    "    train_unique = train_cp.drop_duplicates(subset='game_session',keep='last')\n",
    "    first = 0\n",
    "    for device in dictionary:\n",
    "        first += 1\n",
    "        cut = train_unique[(train_unique['installation_id'] == device)]\n",
    "        for idx,row in cut.iloc[::-1].iterrows():\n",
    "            if row['type'] == 'Assessment':\n",
    "                if first == 1:\n",
    "                    rmidx = train_cp[(train_cp.index > idx) & (train_cp.index <= dictionary[device])].index\n",
    "                else:\n",
    "                    rmidx = rmidx.append(train_cp[(train_cp.index > idx) & (train_cp.index <= dictionary[device])].index)\n",
    "                break\n",
    "        if first % 100 == 0:\n",
    "            print(\"processed\",first,\"ids\")\n",
    "    # drop the events\n",
    "    print(\"dropping events, now we have valid training set:train\")\n",
    "    ptrain = train.drop(index=rmidx)\n",
    "    \n",
    "    #3,output testformatset, and raw_y\n",
    "    # to further split last assessment for each installation_id\n",
    "    train_cp = ptrain.loc[:,['game_session','type','installation_id']]\n",
    "    unique = train_cp.drop_duplicates(subset='game_session',keep='last')\n",
    "    lastassessment = unique.drop_duplicates(subset='installation_id',keep='last')\n",
    "    fullresults = ptrain[ptrain['game_session'].isin(lastassessment.game_session)]\n",
    "    firstlast = fullresults.loc[:,['game_session','installation_id']].drop_duplicates(subset='installation_id',keep='first')\n",
    "    dropindex = fullresults[~fullresults.index.isin(firstlast.index)].index\n",
    "    opt1 = ptrain[~ptrain.index.isin(dropindex)]\n",
    "    # return, 1:all full last assessment for each installation_id\n",
    "    #         2:2nd- end events removed for the last assessment for each installation id, should be same withtest\n",
    "    return fullresults, opt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100 ids\n",
      "processed 200 ids\n",
      "processed 300 ids\n",
      "processed 400 ids\n",
      "processed 500 ids\n",
      "processed 600 ids\n",
      "processed 700 ids\n",
      "processed 800 ids\n",
      "processed 900 ids\n",
      "processed 1000 ids\n",
      "processed 1100 ids\n",
      "processed 1200 ids\n",
      "processed 1300 ids\n",
      "processed 1400 ids\n",
      "processed 1500 ids\n",
      "processed 1600 ids\n",
      "processed 1700 ids\n",
      "processed 1800 ids\n",
      "processed 1900 ids\n",
      "processed 2000 ids\n",
      "processed 2100 ids\n",
      "processed 2200 ids\n",
      "processed 2300 ids\n",
      "processed 2400 ids\n",
      "processed 2500 ids\n",
      "processed 2600 ids\n",
      "processed 2700 ids\n",
      "processed 2800 ids\n",
      "processed 2900 ids\n",
      "processed 3000 ids\n",
      "processed 3100 ids\n",
      "processed 3200 ids\n",
      "processed 3300 ids\n",
      "processed 3400 ids\n",
      "processed 3500 ids\n",
      "processed 3600 ids\n",
      "processed 3700 ids\n",
      "processed 3800 ids\n",
      "processed 3900 ids\n",
      "processed 4000 ids\n",
      "processed 4100 ids\n",
      "processed 4200 ids\n",
      "dropping events, now we have valid training set:train\n"
     ]
    }
   ],
   "source": [
    "raw_y,train_ready = train_clean(raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_y.to_csv('raw_y.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ready.to_csv('train_ready.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
